{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import ldaseqmodel\n",
    "import time\n",
    "from gensim.models.wrappers import DtmModel\n",
    "import pickle\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in csv file\n",
    "all_data = pd.read_csv('./all_data.csv', header=None)\n",
    "# add columns\n",
    "all_data.columns = [\"year\", \"title\", \"article\"]\n",
    "# sort by year\n",
    "all_data = all_data.sort_values(by=['year'])\n",
    "# change index\n",
    "new_index = np.arange(0, len(all_data))\n",
    "all_data[\"new_index\"] = new_index\n",
    "all_data = all_data.set_index('new_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the stop word list\n",
    "stopwords = [line.strip() for line in open(\"stop_words_copy2.txt\",encoding='UTF-8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the function that preprocess the text\n",
    "def preprocess(text):\n",
    "    '''\n",
    "    Preprocess the text by tokenizing the string into uni-grams, deleting all \n",
    "    numbers, punctuations and stop words. Store the preprocessed sting into \n",
    "    a list of words\n",
    "    \n",
    "    input: \n",
    "        text: text for preprocessing(str)\n",
    "    output: a list of words\n",
    "    '''\n",
    "    result = []\n",
    "    tokens = gensim.utils.tokenize(text)\n",
    "    tokens_lst = list(tokens)\n",
    "    for token in tokens_lst:\n",
    "        if token not in stopwords:\n",
    "            result.append(token)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "processed_df = all_data['article'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare Document-Term Matrix for the DTA model \n",
    "# Create Dictionaries for unique word counts of each decade\n",
    "dic_all = corpora.Dictionary(processed_df)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus_all = [dic_all.doc2bow(text) for text in processed_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the time slice\n",
    "all_data[all_data['year']==1958]\n",
    "# before 60s: 0-35\n",
    "all_data[all_data['year']==1978]\n",
    "# before 1979: 36-70\n",
    "all_data[all_data['year']==1989]\n",
    "# before 1990: 71-876\n",
    "all_data[all_data['year']==2003]\n",
    "# before 2003: 877-1811\n",
    "time_slice = [71, 806, 935]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/gensim/models/ldaseqmodel.py:293: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  convergence = np.fabs((bound - old_bound) / old_bound)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19464.67514872551\n"
     ]
    }
   ],
   "source": [
    "# fit the 15-topic model\n",
    "start = time.time()\n",
    "ldaseq_15 = ldaseqmodel.LdaSeqModel(corpus=corpus_all, id2word=dic_all, time_slice=time_slice, \n",
    "                                    num_topics=15, chain_variance=0.13, random_state=100)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "pickle.dump(ldaseq_15, open(\"ldaseq_model_15.sav\", 'wb'))\n",
    "# check\n",
    "loaded_model_15 = pickle.load(open(\"ldaseq_model_15.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U_mass topic coherence\n",
      "DTM Python coherence is -1.4068604518005443\n"
     ]
    }
   ],
   "source": [
    "# calculate coherence matrix\n",
    "topics_dtm_15 = ldaseq_15.dtm_coherence(time=0)\n",
    "cm_DTM_15 = CoherenceModel(topics=topics_dtm_15, corpus=corpus_all, dictionary=dic_all, coherence='u_mass')\n",
    "print (\"U_mass topic coherence\")\n",
    "print (\"DTM Python coherence is\", cm_DTM_15.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U_mass topic coherence\n",
      "DTM Python coherence is -1.283978424278397\n"
     ]
    }
   ],
   "source": [
    "# calculate coherence matrix\n",
    "topics_dtm_15_test = loaded_model_15.dtm_coherence(time=2)\n",
    "cm_DTM_15_test = CoherenceModel(topics=topics_dtm_15_test, corpus=corpus_all, dictionary=dic_all, coherence='u_mass')\n",
    "print (\"U_mass topic coherence\")\n",
    "print (\"DTM Python coherence is\", cm_DTM_15_test.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
